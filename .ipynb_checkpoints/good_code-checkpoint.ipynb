{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AB testing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "experiment_gr = df.query(\"group == 'experiment'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-sampling"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_train, y_train = make_imbalance(X_train, y_train, sampling_strategy={0: 1150, 1: 1150, 2: 1150},random_state=14)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def upsample_data(X_tr,y_tr,random_seed):\n",
    "    \"\"\"\n",
    "    Input X and y training data from an unbalanced data set to upsample the minority class for a more meaningful model\n",
    "    \"\"\"\n",
    "    training  = pd.concat([X_tr, y_tr], axis=1)\n",
    "    class_0 = training[training.Target==0]\n",
    "    class_1 = training[training.Target==1]\n",
    "    class_1_upsampled = resample(class_1,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(class_0), # match number in majority class\n",
    "                          random_state=random_seed) # reproducible results\n",
    "    upsampled = pd.concat([class_0, class_1_upsampled])\n",
    "    y_tr = upsampled.Target\n",
    "    X_tr = upsampled.drop('Target', axis=1)\n",
    "    return X_tr,y_tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical features"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def show_categorical_breakdown(dataframe):\n",
    "    cat_cols = []\n",
    "    cat_col_vals = []\n",
    "    for col in cat_list[1:]:\n",
    "        cat_cols.append(col) \n",
    "        cat_col_vals.append(dataframe[col].nunique())\n",
    "    print (col,df[col].nunique())\n",
    "    plt.tight_layout()\n",
    "    plt.figure(figsize=(15,8))\n",
    "    return plt.barh(cat_cols,cat_col_vals)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for cat in cat_list:\n",
    "    dummy_df = df[[cat,'Target']].groupby([cat],as_index=False).mean()\n",
    "    dummy_dict = {}\n",
    "    for i in range(len(dummy_df)):\n",
    "        dummy_dict[dummy_df.iloc[i,0]]=float(dummy_df.iloc[i,1])\n",
    "    df[cat] = df[cat].map(lambda x: dummy_dict[x])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for cat in cat_list:\n",
    "    df[cat] = df[cat].astype(float)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "categorical_features = X_train.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and preparation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def filter_outliers(dataframe,threshold):\n",
    "    \"\"\"\n",
    "    Input a data frame and have all outliers filtered to a certain and custom threshold of standard deviations\n",
    "    \"\"\"\n",
    "    dataframe = dataframe[(np.abs(stats.zscore(dataframe)) <= threshold).all(axis=1)]\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def normalize_features(dataframe):\n",
    "    \"\"\"\n",
    "    Input a data frame and use Box-Cox transform to normalize data\n",
    "    \"\"\"\n",
    "    for col in dataframe.columns:\n",
    "        dataframe[col]=list(stats.boxcox(abs(dataframe[col]+0.01)))[0]\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def min_max_scale_data(dataframe):\n",
    "    \"\"\"\n",
    "    Input a data frame and scale data using Min-Max scaling\n",
    "    \"\"\"\n",
    "    scaler = MinMaxScaler()\n",
    "    for col in dataframe.columns:\n",
    "        if (dataframe[col]>=1).sum() >0:\n",
    "            dataframe[col] = scaler.fit_transform(dataframe[[col]])\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Step 1 - survey data and maske binning decision\n",
    "## Step 2 - ask questions without looking at data (keep in mind a target imbalance and may want hue to be target to eliminate bias)\n",
    "## Step 3 - figure out what comparisons or relationships you want to explore with target variable (max three per feature)\n",
    "## Step 4 - figure out how you want features to relate to each other (max four visuals per feaature)\n",
    "## Step 5 - keep list to track inquiries"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "palette\n",
    "\n",
    "[‘Accent’, ‘Accent_r’, ‘Blues’, ‘Blues_r’, ‘BrBG’, ‘BrBG_r’, ‘BuGn’, ‘BuGn_r’, ‘BuPu’, ‘BuPu_r’, \n",
    " ‘CMRmap’, ‘CMRmap_r’, ‘Dark2’, ‘Dark2_r’, ‘GnBu’, ‘GnBu_r’, ‘Greens’, ‘Greens_r’, ‘Greys’, ‘Greys_r’, ‘OrRd’, \n",
    " ‘OrRd_r’, ‘Oranges’, ‘Oranges_r’, ‘PRGn’, ‘PRGn_r’, ‘Paired’, ‘Paired_r’, ‘Pastel1’, \n",
    " ‘Pastel1_r’, ‘Pastel2’, ‘Pastel2_r’, ‘PiYG’, ‘PiYG_r’, ‘PuBu’, ‘PuBuGn’, ‘PuBuGn_r’, \n",
    " ‘PuBu_r’, ‘PuOr’, ‘PuOr_r’, ‘PuRd’, ‘PuRd_r’, ‘Purples’, ‘Purples_r’, ‘RdBu’, ‘RdBu_r’, \n",
    " ‘RdGy’, ‘RdGy_r’, ‘RdPu’, ‘RdPu_r’, ‘RdYlBu’, ‘RdYlBu_r’, ‘RdYlGn’, ‘RdYlGn_r’, ‘Reds’, \n",
    " ‘Reds_r’, ‘Set1’, ‘Set1_r’, ‘Set2’, ‘Set2_r’, ‘Set3’, ‘Set3_r’, ‘Spectral’, ‘Spectral_r’, \n",
    " ‘Wistia’, ‘Wistia_r’, ‘YlGn’, ‘YlGnBu’, ‘YlGnBu_r’, ‘YlGn_r’, ‘YlOrBr’, ‘YlOrBr_r’, ‘YlOrRd’, \n",
    " ‘YlOrRd_r’, ‘afmhot’, ‘afmhot_r’, ‘autumn’, ‘autumn_r’, ‘binary’, ‘binary_r’, ‘bone’, \n",
    " ‘bone_r’, ‘brg’, ‘brg_r’, ‘bwr’, ‘bwr_r’, ‘cividis’, ‘cividis_r’, ‘cool’, ‘cool_r’, ‘coolwarm’, ‘coolwarm_r’, ‘copper’, ‘copper_r’,\n",
    " ‘cubehelix’, ‘cubehelix_r’, ‘flag’, ‘flag_r’, ‘gist_earth’, ‘gist_earth_r’, ‘gist_gray’, ‘gist_gray_r’, ‘gist_heat’, ‘gist_heat_r’, ‘gist_ncar’, ‘gist_ncar_r’,\n",
    " ‘gist_rainbow’, ‘gist_rainbow_r’, ‘gist_stern’, ‘gist_stern_r’, ‘gist_yarg’, \n",
    " ‘gist_yarg_r’, ‘gnuplot’, ‘gnuplot2’, ‘gnuplot2_r’, ‘gnuplot_r’, ‘gray’, ‘gray_r’,\n",
    " ‘hot’, ‘hot_r’, ‘hsv’, ‘hsv_r’, ‘icefire’, ‘icefire_r’, ‘inferno’, \n",
    " ‘inferno_r’, ‘magma’, ‘magma_r’, ‘mako’, ‘mako_r’, \n",
    " ‘nipy_spectral’, ‘nipy_spectral_r’, ‘ocean’, ‘ocean_r’, ‘pink’, ‘pink_r’,\n",
    " ‘plasma’, ‘plasma_r’, ‘prism’, ‘prism_r’, ‘rainbow’, ‘rainbow_r’,\n",
    " ‘rocket’, ‘rocket_r’, ‘seismic’, ‘seismic_r’, ‘spring’, ‘spring_r’,\n",
    " ‘summer’, ‘summer_r’, ‘tab10’, ‘tab10_r’, ‘tab20’, ‘tab20_r’, ‘tab20b’,\n",
    " ‘tab20b_r’, ‘tab20c’, ‘tab20c_r’, ‘terrain’, ‘terrain_r’, ‘twilight’,\n",
    " ‘twilight_r’, ‘twilight_shifted’, ‘twilight_shifted_r’, ‘viridis’, ‘viridis_r’, ‘vlag’, ‘vlag_r’, ‘winter’, ‘winter_r’]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cmap\n",
    "\n",
    "['Accent', 'Accent_r', 'Blues', 'Blues_r', 'BrBG', 'BrBG_r', 'BuGn', 'BuGn_r', 'BuPu', 'BuPu_r', 'CMRmap', 'CMRmap_r', 'Dark2', 'Dark2_r', 'GnBu', 'GnBu_r', 'Greens', 'Greens_r', 'Greys', 'Greys_r', 'OrRd', 'OrRd_r', 'Oranges', 'Oranges_r', 'PRGn', 'PRGn_r', 'Paired', 'Paired_r', 'Pastel1', 'Pastel1_r', 'Pastel2', 'Pastel2_r', 'PiYG', 'PiYG_r', 'PuBu', 'PuBuGn', 'PuBuGn_r', 'PuBu_r', 'PuOr', 'PuOr_r', 'PuRd', 'PuRd_r', 'Purples', 'Purples_r', 'RdBu', 'RdBu_r', 'RdGy', 'RdGy_r', 'RdPu', 'RdPu_r', 'RdYlBu', 'RdYlBu_r', 'RdYlGn', 'RdYlGn_r', 'Reds', 'Reds_r', 'Set1', 'Set1_r', 'Set2', 'Set2_r', 'Set3', 'Set3_r', 'Spectral', 'Spectral_r', 'Wistia', 'Wistia_r', 'YlGn', 'YlGnBu', 'YlGnBu_r', 'YlGn_r', 'YlOrBr', 'YlOrBr_r', 'YlOrRd', 'YlOrRd_r', 'afmhot', 'afmhot_r', 'autumn', 'autumn_r', 'binary', 'binary_r', 'bone', 'bone_r', 'brg', 'brg_r', 'bwr', 'bwr_r', 'cividis', 'cividis_r', 'cool', 'cool_r', 'coolwarm', 'coolwarm_r', 'copper', 'copper_r', 'cubehelix', 'cubehelix_r', 'flag', 'flag_r', 'gist_earth', 'gist_earth_r', 'gist_gray', 'gist_gray_r', 'gist_heat', 'gist_heat_r', 'gist_ncar', 'gist_ncar_r', 'gist_rainbow', 'gist_rainbow_r', 'gist_stern', 'gist_stern_r', 'gist_yarg', 'gist_yarg_r', 'gnuplot', 'gnuplot2', 'gnuplot2_r', 'gnuplot_r', 'gray', 'gray_r', 'hot', 'hot_r', 'hsv', 'hsv_r', 'inferno', 'inferno_r', 'jet', 'jet_r', 'magma', 'magma_r', 'nipy_spectral', 'nipy_spectral_r', 'ocean', 'ocean_r', 'pink', 'pink_r', 'plasma', 'plasma_r', 'prism', 'prism_r', 'rainbow', 'rainbow_r', 'seismic', 'seismic_r', 'spring', 'spring_r', 'summer', 'summer_r', 'tab10', 'tab10_r', 'tab20', 'tab20_r', 'tab20b', 'tab20b_r', 'tab20c', 'tab20c_r', 'terrain', 'terrain_r', 'viridis', 'viridis_r', 'winter', 'winter_r']\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.subplot(1,1,1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df.boxplot('weight', by = 'group')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "g = sns.violinplot(x=df.Pos ,y=df.Age)\n",
    "g.set_xticklabels(labels=set(df.Pos),rotation=45)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.axes_style()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with sns.plotting_context(\"paper\") and sns.axes_style('darkgrid') and and sns.color_palette(palette=''):"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20,12))\n",
    "plt.tight_layout()\n",
    "sns.heatmap(df.corr()>=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#### stacked bar\n",
    "\n",
    "with sns.axes_style('darkgrid',{'axes.facecolor': 'whitesmoke'}):\n",
    "\n",
    "    labels_1 = ['Contract', 'Group', 'Transient', 'Trasnsient-Party']\n",
    "    city_means = [0.25, 0.088, 0.324, 0.167]\n",
    "    resort_means = [0.086, 0.109, 0.263, 0.129]\n",
    "    city_std = [0.433, 0.284, 0.468, 0.373]\n",
    "    resort_std = [0.28, 0.313, 0.44, 0.335]\n",
    "\n",
    "    plt.figure(figsize=(15,8))\n",
    "\n",
    "    width = 0.75\n",
    "    plt.bar(labels_1, resort_means, width, yerr=city_std, label='City',color='pink',edgecolor='limegreen')\n",
    "    plt.bar(labels_1, city_means, width, yerr=resort_std, bottom=resort_means,label='Resort',color='aqua',edgecolor='black')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#### stacked area\n",
    "\n",
    "labels_2 = ['Contract', 'Group', 'Transient', 'Trasnsient-Party']\n",
    "x = labels_2\n",
    "low_lead = [0.15,0.07,0.29,0.14]\n",
    "mid_lead = [0.23,0.49,0.58,0.22]\n",
    "high_lead = [0,0,0.96,0.13]\n",
    "y = [low_lead,mid_lead,high_lead]\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "\n",
    "width = 0.5\n",
    "plt.stackplot(x,y)\n",
    "plt.tight_layout()\n",
    "plt.title('likelihood of cancelation based on vertical groupings of lead time',color='black')\n",
    "\n",
    "plt.title\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.relplot(x=\"passengers\", y=\"month\", hue=\"year\", data=f);\n",
    "\n",
    "numerical by categorical"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lineplot"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.catplot(x=\"day\", y=\"total_bill\", data=a);\n",
    "\n",
    "cat by num"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "b = sns.FacetGrid(a, col=\"species\") \n",
    "\n",
    "b.map(plt.hist, \"sepal_length\")\n",
    "\n",
    "multiple subplots of histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis testing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def cohen_d(x,y):\n",
    "    nx = len(x)\n",
    "    ny = len(y)\n",
    "    dof = nx + ny - 2\n",
    "    return (np.mean(x) - np.mean(y)) / (np.sqrt(((nx-1)*np.std(x, ddof=1) ** 2 + (ny-1)*np.std(y, ddof=1) ** 2) / dof))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "stats.f_oneway(frdm_mm['Trade Freedom'],frdm_mm['Investment Freedom '],frdm_mm['Labor Freedom'],frdm_mm['Monetary Freedom'],frdm_mm['Financial Freedom'],frdm_mm['Labor Freedom'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from numpy import array\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.stats.power import TTestIndPower\n",
    "# parameters for power analysis\n",
    "effect_sizes = np.linspace(0.1,0.2821601557256289+0.3,5)\n",
    "sample_sizes = array(range(30, 100))\n",
    "# calculate power curves from multiple power analyses\n",
    "analysis = TTestIndPower()\n",
    "analysis.plot_power(dep_var='nobs', nobs=sample_sizes, effect_size=effect_sizes)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFE / PCA"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## this code is designed to find the number of features needed in the X data for an optimal accuracy score\n",
    "\n",
    "def optimize_score_rfe(scaler, dataframe,method,style,target_variable,ts,cross_val=5,goal='accuracy'):\n",
    "    \n",
    "    \"\"\"\n",
    "    Input a goal, method, style (the method of analysis written as a string), and number of cross validations and \n",
    "    receive an optimal score, number of features used, and list of features used as an output\n",
    "    \"\"\"\n",
    "    \n",
    "    # Imports and initializing variables\n",
    "    mms = scaler\n",
    "    old_score = 0\n",
    "    old_features_used = 1\n",
    "\n",
    "    # Optimize features needed\n",
    "    for i in range(1,df.shape[1]):\n",
    "        y = dataframe.Target\n",
    "        X = dataframe.drop('Target',axis=1)\n",
    "        selector = RFE(method,n_features_to_select=i)\n",
    "        # selector = RFECV(estimator=method, step=1, cv=StratifiedKFold(cross_val), scoring=goal,min_features_to_select=i)\n",
    "        selector = selector.fit(X, y.values.ravel())\n",
    "        selected_columns = X.columns[selector.support_]\n",
    "        new_y = dataframe.Target\n",
    "        new_X = dataframe[selected_columns]\n",
    "        for col in new_X.columns:\n",
    "            new_X[col] = mms.fit_transform(new_X[[col]])\n",
    "        X_train, X_test, y_train, y_test = train_test_split(new_X,new_y,test_size=ts,random_state=14) \n",
    "        method.fit(X_train,y_train)\n",
    "        Y_pred = method.predict(X_test)\n",
    "        if style == 'Linear_Regression':\n",
    "            accuracy = r2_score(y_test, Y_pred)\n",
    "        else:\n",
    "            accuracy = accuracy_score(y_test, Y_pred)\n",
    "        new_score = accuracy\n",
    "        if new_score > old_score:\n",
    "            score = new_score\n",
    "            features_used = i\n",
    "            old_score = new_score\n",
    "            old_features_used = i\n",
    "        else:\n",
    "            score = old_score\n",
    "            features_used = old_features_used\n",
    "    \n",
    "        # crate new data frame based on work\n",
    "        # selector_new = RFECV(estimator=method, step=1, cv=StratifiedKFold(cross_val), scoring='accuracy',min_features_to_select=features_used)\n",
    "        selector_new = RFE(method,n_features_to_select=features_used)\n",
    "        selector_new = selector_new.fit(X, y.values.ravel())\n",
    "        selected_columns_new = X.columns[selector_new.support_]\n",
    "        \n",
    "    # print discoveries\n",
    "    print(f'Predicting: {target_variable}')\n",
    "    print('')\n",
    "    print(f'The optimal score is {100*round(score,2)}%, and it makes use of {features_used} features from the data.')\n",
    "    print('')\n",
    "    print(f'Those features are: {list(selected_columns_new)}')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "pca.fit(X_train)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)*100\n",
    "d = [n for n in range(len(cumsum))]\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(d, cumsum, color='red', label = 'Explained Variance')\n",
    "plt.title('Explained Variance vs Number of Components')\n",
    "plt.ylabel('Explained Variance')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.axhline(y = 90, color='k', linestyle='--', label = '90% of Explained Variance')\n",
    "plt.xlim(0,40)\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pca_fraud = PCA(n_components=16)\n",
    "X_train_pca = pd.DataFrame(pca_fraud.fit_transform(X_train))\n",
    "X_test_pca = pd.DataFrame(pca_fraud.transform(X_test))\n",
    "train_pca = X_train_pca.copy()\n",
    "train_pca['fraud_reported']=y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lst_1 = list(coef_df.T[::-1].index)\n",
    "lst_2 = [float(x) for x in coef_df.T[::-1].values]\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.tight_layout()\n",
    "plt.barh(lst_1,lst_2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import eli5\n",
    "\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "p = PermutationImportance(rf1, random_state=14).fit(X_train,y_train)\n",
    "\n",
    "eli5.show_weights(p, feature_names = X_train.columns.tolist())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "feature_importance = pd.DataFrame(lr.coef_).T\n",
    "feature_importance.columns = X_new.columns\n",
    "\n",
    "sorted_fi = feature_importance.T.sort_values(by=0,ascending=False)\n",
    "sorted_fi"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# create data frames to summarize findings\n",
    "models = pd.DataFrame({\n",
    "    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n",
    "              'Random Forest', 'Naive Bayes', \n",
    "              'Stochastic Gradient Decent', 'Linear SVC', \n",
    "              'Decision Tree','XGBoost'],\n",
    "    'Score': [acc_svc, acc_knn, acc_log, acc_random_forest, acc_gaussian, acc_sgd, acc_linear_svc, acc_decision_tree, acc_xg]})\n",
    "models = models.sort_values(by='Score', ascending=False).T\n",
    "precision_df = pd.DataFrame({\n",
    "    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n",
    "              'Random Forest', 'Naive Bayes', \n",
    "              'Stochastic Gradient Decent', 'Linear SVC', \n",
    "              'Decision Tree','XGBoost'],\n",
    "    'Precision': [p_score_svc, p_score_knn, p_score_lr, p_score_rf, p_score_gnb, p_score_sgd, p_score_lsvc, p_score_dt,p_xg]})\n",
    "precision_df = precision_df.sort_values(by='Precision', ascending=False).T\n",
    "recall_df = pd.DataFrame({\n",
    "    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n",
    "              'Random Forest', 'Naive Bayes', \n",
    "              'Stochastic Gradient Decent', 'Linear SVC', \n",
    "              'Decision Tree','XGBoost'],\n",
    "    'Recall': [r_score_svc, r_score_knn, r_score_lr, r_score_rf, r_score_gnb, r_score_sgd, r_score_lsvc, r_score_dt,r_xg]})\n",
    "recall_df = recall_df.sort_values(by='Recall', ascending=False).T\n",
    "f1_df = pd.DataFrame({\n",
    "    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n",
    "              'Random Forest', 'Naive Bayes', \n",
    "              'Stochastic Gradient Decent', 'Linear SVC', \n",
    "              'Decision Tree','XGB oost'],\n",
    "    'F1-Score': [f1_svc, f1_knn, f1_lr, f1_rf, f1_gnb, f1_sgd, f1_lsvc, f1_dt,f1_xg]})\n",
    "f1_df = f1_df.sort_values(by='F1-Score', ascending=False).T"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Logistic Regression grid search for optimal parameters\n",
    "grid={\"C\":np.logspace(-10,10,20), \"penalty\":[\"l1\",\"l2\"],'dual':[False,True],'fit_intercept':[True,False],\n",
    "      'multi_class':['auto','ovr','multinomial']}\n",
    "logreg=LogisticRegression(random_state=seed)\n",
    "logreg_cv=GridSearchCV(logreg,grid,cv=10)\n",
    "logreg_cv.fit(X_train,y_train)\n",
    "print(\"tuned hpyerparameters :(best parameters) \",logreg_cv.best_params_)\n",
    "print(\"accuracy :\",logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# solve for auc score\n",
    "fpr, tpr, threshold = roc_curve(y_test, Y_pred)\n",
    "print(auc(fpr,tpr), threshold)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Support Vector Machine grid search for optimal parameters\n",
    "from sklearn.model_selection import GridSearchCV  \n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],  'gamma': [1, 0.1, 0.01, 0.001, 0.0001]}  \n",
    "grid = GridSearchCV(SVC(random_state=seed), param_grid, refit = True, verbose = 3) \n",
    "grid.fit(X_train, y_train) \n",
    "print(grid.best_params_) \n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## KNN grid search for optimal parameters\n",
    "grid_params = {'n_neighbors':[3,5,7,9,11,13],'weights':['uniform','distance'],'metric':['euclidean','manhattan','minkowski']}\n",
    "gs = GridSearchCV(KNeighborsClassifier(),grid_params,verbose=1,cv = 5,n_jobs = -1)\n",
    "gs_results = gs.fit(X_train,y_train)\n",
    "print(gs.best_score_)\n",
    "print('')\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Linear SVC grid search for optimal parameters\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],  'penalty': ['l1','l2'],'dual':[True,False],}  \n",
    "grid = GridSearchCV(LinearSVC(random_state=seed), param_grid, refit = True, verbose = 3) \n",
    "grid.fit(X_train, y_train) \n",
    "print(grid.best_params_) \n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Decision Tree grid search for optimal parameters\n",
    "param_grid = {'max_depth':[1,2,3,4,5,6,7,8,9],'min_samples_leaf':[1,2,3,4,5],'max_features':['max','sqrt','log2']}  \n",
    "grid = GridSearchCV(DecisionTreeClassifier(random_state=seed), param_grid, refit = True, verbose = 3) \n",
    "grid.fit(X_train, y_train) \n",
    "print(grid.best_params_) \n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Random Forest grid search for optimal parameters\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "random_grid = {'n_estimators': n_estimators,'max_features': max_features,'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,'min_samples_leaf': min_samples_leaf,'bootstrap': bootstrap}\n",
    "rf = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "rf_random.fit(X_train, y_train)\n",
    "print(rf_random.best_params_)\n",
    "print(rf_random.best_score_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# XGBoost grid search for optimal parameters\n",
    "param_grid = {'max_depth': range (2, 10),'n_estimators': range(2, 30),\"min_child_weight\" : [1,3,5],\n",
    "             \"gamma\":[0.0,0.2,0.4],\"colsample_bytree\":[0.3,0.4,0.5,0.7]}  \n",
    "grid = GridSearchCV(XGBClassifier(random_state=seed), param_grid, refit = True, verbose = 3) \n",
    "grid.fit(X_train, y_train) \n",
    "print(grid.best_params_) \n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# this block of code creates a visual of a decision tree\n",
    "\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "dot_data = StringIO()\n",
    "export_graphviz(decision_tree, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True,max_depth=3,feature_names=X_train.columns)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def create_polynomial_regression_model(degree,model_type,ts=0.25):\n",
    "    \n",
    "    \"Creates a polynomial regression model for the given degree\"\n",
    "  \n",
    "    poly_features = PolynomialFeatures(degree=degree)\n",
    "  \n",
    "    # transforms the existing features to higher degree features.\n",
    "    X_train_poly = poly_features.fit_transform(X_train)\n",
    "  \n",
    "    # fit the transformed features to Linear Regression\n",
    "    poly_model = model_type\n",
    "    poly_model.fit(X_train_poly, y_train)\n",
    "  \n",
    "    # predicting on training data-set\n",
    "    y_train_predicted = poly_model.predict(X_train_poly)\n",
    "  \n",
    "    # predicting on test data-set\n",
    "    y_test_predict = poly_model.predict(poly_features.fit_transform(X_test))\n",
    "  \n",
    "    # Linear Regression\n",
    "    if model_type == LinearRegression():\n",
    "        # evaluating the model on training dataset\n",
    "        train_score = round(r2_score(y_train, y_train_predicted),3)\n",
    "  \n",
    "        # evaluating the model on test dataset\n",
    "        test_score = round(r2_score(y_test, y_test_predict),3)\n",
    "    \n",
    "    # Classification\n",
    "    else:\n",
    "        train_score = round(accuracy_score(y_train,y_train_predicted),3)\n",
    "        test_score = round(accuracy_score(y_test, y_test_predict),3)\n",
    "    \n",
    "  \n",
    "    print(\"The model performance for the training set\")\n",
    "    print(\"-------------------------------------------\")\n",
    "    print(\"Score of training set is {}\".format(train_score))\n",
    "  \n",
    "    print(\"\\n\")\n",
    "  \n",
    "    print(\"The model performance for the test set\")\n",
    "    print(\"-------------------------------------------\")\n",
    "    print(\"Score of test set is {}\".format(test_score))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def ridge_reg_score(X_tr,y_tr,X_val,y_val,alpha):\n",
    "    \"\"\"\n",
    "    Check scores after applying ridge regularization\n",
    "    \"\"\"\n",
    "    ridge_reg = Ridge(alpha=0.05)\n",
    "    ridge_reg.fit(X_tr,y_tr)\n",
    "    ridge_coef = pd.DataFrame(ridge_reg.coef_).T\n",
    "    ridge_coef.columns = X_tr.columns\n",
    "    ridge_score = ridge_reg.score(X_val,y_val)\n",
    "    return ridge_score,ridge_coef"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "start=dt.datetime.now()\n",
    "print('Elapsed time: ',str(dt.datetime.now()-start))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "stopwords_list = stopwords.words('english') + list(string.punctuation)\n",
    "stopwords_list += [\"''\", '\"\"', '...', '``']\n",
    "def process_review(review):\n",
    "    tokens = nltk.word_tokenize(review)\n",
    "    stopwords_removed = [token.lower() for token in tokens if token.lower() not in stopwords_list]\n",
    "    return stopwords_removed\n",
    "total_vocab = set()\n",
    "for review in processed_data:\n",
    "    total_vocab.update(review)\n",
    "len(total_vocab)\n",
    "review_concat = []\n",
    "for review in processed_data:\n",
    "    review_concat += review\n",
    "review_freqdist = FreqDist(review_concat)\n",
    "review_freqdist.most_common(20)\n",
    "tf_idf_data_train = vectorizer.fit_transform(X_train)\n",
    "tf_idf_data_test = vectorizer.transform(X_test)\n",
    "nb_classifier = MultinomialNB()\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100)\n",
    "nb_classifier.fit(tf_idf_data_train, y_train)\n",
    "nb_train_preds = nb_classifier.predict(tf_idf_data_train)\n",
    "nb_test_preds = nb_classifier.predict(tf_idf_data_test)\n",
    "rf_classifier.fit(tf_idf_data_train, y_train)\n",
    "rf_train_preds = rf_classifier.predict(tf_idf_data_train)\n",
    "rf_test_preds = rf_classifier.predict(tf_idf_data_test)\n",
    "nb_train_score = accuracy_score(y_train, nb_train_preds)\n",
    "nb_test_score = accuracy_score(y_test, nb_test_preds)\n",
    "rf_train_score = accuracy_score(y_train, rf_train_preds)\n",
    "rf_test_score = accuracy_score(y_test, rf_test_preds)\n",
    "\n",
    "print(\"Multinomial Naive Bayes\")\n",
    "print(\"Training Accuracy: {:.4} \\t\\t Testing Accuracy: {:.4}\".format(nb_train_score, nb_test_score))\n",
    "print(\"\")\n",
    "print('-'*80)\n",
    "print(\"\")\n",
    "print('Random Forest')\n",
    "print(\"Training Accuracy: {:.4} \\t\\t Testing Accuracy: {:.4}\".format(rf_train_score, rf_test_score))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# fill NA values by space\n",
    "df['Review Text'] = df['Review Text'].fillna('')\n",
    "\n",
    "# CountVectorizer() converts a collection \n",
    "# of text documents to a matrix of token counts\n",
    "vectorizer = CountVectorizer()\n",
    "# assign a shorter name for the analyze\n",
    "# which tokenizes the string\n",
    "analyzer = vectorizer.build_analyzer()\n",
    "\n",
    "def wordcounts(s):\n",
    "    c = {}\n",
    "    # tokenize the string and continue, if it is not empty\n",
    "    if analyzer(s):\n",
    "        d = {}\n",
    "        # find counts of the vocabularies and transform to array \n",
    "        w = vectorizer.fit_transform([s]).toarray()\n",
    "        # vocabulary and index (index of w)\n",
    "        vc = vectorizer.vocabulary_\n",
    "        # items() transforms the dictionary's (word, index) tuple pairs\n",
    "        for k,v in vc.items():\n",
    "            d[v]=k # d -> index:word \n",
    "        for index,i in enumerate(w[0]):\n",
    "            c[d[index]] = i # c -> word:count\n",
    "    return  c\n",
    "\n",
    "# add new column to the dataframe\n",
    "df['Word Counts'] = df['Review Text'].apply(wordcounts)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.figure(figsize = (13, 8), facecolor = None) \n",
    "\n",
    "wc = WordCloud(width = 1000, height = 600, background_color='white', max_words=15, margin = 10).generate(str(df['Word Counts']))\n",
    "plt.tight_layout\n",
    "plt.imshow(wc) \n",
    "plt.axis(\"off\") \n",
    "plt.tight_layout(pad = 0) \n",
    "  \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['blurb'], df['state'], train_size=0.8)\n",
    "vectorizer = TfidfVectorizer().fit(x_train)\n",
    "x_train_v = vectorizer.transform(x_train)\n",
    "x_test_v  = vectorizer.transform(x_test)\n",
    "lr = LogisticRegression(random_state=14)\n",
    "lr.fit(x_train_v,y_train)\n",
    "Y_pred = lr.predict(x_test_v)\n",
    "print(f'{round(accuracy_score(y_test,Y_pred)*100,2)}%')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# mess around with different optimizers, metrics, loss functions, and activations\n",
    "model = keras.Sequential([keras.layers.Flatten(input_shape=(28,28)),\n",
    "                         keras.layers.Dense(128, activation=\"relu\"),\n",
    "                          keras.layers.Dense(10, activation='softmax')\n",
    "                         ])\n",
    "model.compile(optimizer = 'adam', loss= 'sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "prediction = model.predict(test_images)\n",
    "for i in range (5):\n",
    "    plt.grid(False)\n",
    "    plt.imshow(test_images[i],cmap=plt.cm.binary)\n",
    "    plt.xlabel('Actual '+class_names[test_labels[i]])\n",
    "    plt.title('Prediction '+class_names[np.argmax(prediction[i])])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rp.summary_cont(df['Target'].groupby(df['variable']))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lr_fpr, lr_tpr, tresh = roc_curve(y_test,pred_lr)\n",
    "auc_lr = auc(lr_fpr,lr_tpr)\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "\n",
    "plt.plot(lr_fpr, lr_tpr, marker='.', label='Logistic (auc = %0.3f)' % auc_lr)\n",
    "\n",
    "plt.xlabel('False Positive Rate -->')\n",
    "plt.ylabel('True Positive Rate -->')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mm = MinMaxScaler()\n",
    "ma = MaxAbsScaler()\n",
    "ss = StandardScaler()\n",
    "rs = RobustScaler()\n",
    "pt = PowerTransformer()\n",
    "qt = QuantileTransformer()\n",
    "mod_acc_list = []\n",
    "for i in [mm,ma,ss,rs,pt,qt]:\n",
    "    scaled_X = i.fit_transform(X.values)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=14,test_size = 0.25)\n",
    "    k = {}\n",
    "    for j in models:\n",
    "        m = j\n",
    "        m.fit(X_train,y_train)\n",
    "        pred = m.predict(X_test)\n",
    "        k[f'{j}'[0:3]] = accuracy_score(y_test,pred)\n",
    "    mod_acc_list.append([f'{i}',k])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rf = RandomForestClassifier()\n",
    "dt = DecisionTreeClassifier()\n",
    "gnb = GaussianNB()\n",
    "lr = LogisticRegression()\n",
    "lsv = LinearSVC()\n",
    "svc = SVC()\n",
    "sgd = SGDClassifier()\n",
    "xgb = XGBClassifier()\n",
    "knn = KNeighborsClassifier()\n",
    "models = [rf,dt,gnb,lr,lsv,svc,sgd,xgb,knn]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mm = MinMaxScaler()\n",
    "ma = MaxAbsScaler()\n",
    "ss = StandardScaler()\n",
    "rs = RobustScaler()\n",
    "pt = PowerTransformer()\n",
    "qt = QuantileTransformer()\n",
    "mod_acc_list = []\n",
    "for i in [mm,ma,ss,rs,pt,qt]:\n",
    "    scaled_X = i.fit_transform(X.values)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=14,test_size = 0.25)\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train,y_train)\n",
    "    pred = lr.predict(X_test)\n",
    "    rsquare = r2_score(y_test,pred)\n",
    "    mod_acc_list.append([f'{i},{rsquare}'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mm = MinMaxScaler()\n",
    "ma = MaxAbsScaler()\n",
    "ss = StandardScaler()\n",
    "rs = RobustScaler()\n",
    "pt = PowerTransformer()\n",
    "qt = QuantileTransformer()\n",
    "mod_acc_list = []\n",
    "for i in [mm,ma,ss,rs,pt,qt]:\n",
    "    X_train_s = i.fit_transform(X_train)\n",
    "    X_test_s = i.fit_transform(X_test)\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=14,test_size = 0.25)\n",
    "    k = {}\n",
    "    for j in models:\n",
    "        m = j\n",
    "        m.fit(X_train_s,y_train)\n",
    "        pred = m.predict(X_test_s)\n",
    "        k[f'{j}'[0:3]] = accuracy_score(y_test,pred)\n",
    "    mod_acc_list.append([f'{i}',k])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "categorical_transformer = Pipeline(steps=[('imputer',SimpleImputer(strategy='constant',\n",
    "                        fill_value='missing')),('onehot',OneHotEncoder(handle_unknown='ignore'))])\n",
    "numeric_transformer = Pipeline(steps=[('imputer',SimpleImputer(strategy='median')),('scaler',QuantileTransformer())])\n",
    "\n",
    "\n",
    "numeric_features = X_train.select_dtypes(include=['int64','float64']).columns\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num',numeric_transformer,numeric_features),\n",
    "    ('cat',categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "\n",
    "rf = Pipeline(steps=[('preprocessor',preprocessor),('classifier',RandomForestClassifier())])\n",
    "\n",
    "\n",
    "rf.fit(X_train,y_train)\n",
    "pred = rf.predict(X_test)\n",
    "print(classification_report(pred,y_test))\n",
    "\n",
    "\n",
    "classifiers=[\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(),\n",
    "    RandomForestClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "]\n",
    "\n",
    "for c in classifiers:\n",
    "    pipe = Pipeline(steps = [('preprocessor',preprocessor),('classifier',c)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    print(str(c)[0:4])\n",
    "    print(pipe.score(X_test, y_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def encode_cat(df, categorical_features):\n",
    "    for cat in categorical_features:\n",
    "        dummy_df = df[[cat,'Target']].groupby([cat],as_index=False).mean()\n",
    "        dummy_dict = {}\n",
    "        for i in range(len(dummy_df)):\n",
    "            dummy_dict[dummy_df.iloc[i,0]]=float(dummy_df.iloc[i,1])\n",
    "        df[cat] = df[cat].map(lambda x: dummy_dict[x])\n",
    "        \n",
    "        \n",
    "categorical_transformer = Pipeline(steps=[('imputer',SimpleImputer(strategy='constant',\n",
    "                        fill_value='missing')),('onehot',OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[('imputer',SimpleImputer(strategy='median')),('scaler',QuantileTransformer())])\n",
    "\n",
    "cat_super_code = Pipeline(steps=[('imputer',SimpleImputer(strategy='constant',fill_value='missing')),\n",
    "                            ('magic',encode_cat(df,categorical_features))])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "numeric_features = X_train.select_dtypes(include=['int64','float64']).columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "    return roc_auc_score(y_test, y_pred, average=average)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import requests\n",
    "import json\n",
    "parameter = {\"rel_rhy\":\"red\"}\n",
    "request = requests.get('https://api.datamuse.com/words',parameter)\n",
    "rhyme_json = request.json()\n",
    "for i in rhyme_json[0:10]:\n",
    "    print(i['word'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "people = requests.get('https://covid-simple.satyawikananda.tech/api/world')\n",
    "print(people.text)\n",
    "\n",
    "people_json = people.json()\n",
    "print(people_json)\n",
    "\n",
    "for p in people_json.items():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "spotipy"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "s = 'ab c'\n",
    "s.replace(\" \", \"\")\n",
    "\n",
    "### 'abc'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df.columns = df.columns.str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### this function takes a 2 by 3 data frame and returns a ttest statistic and power metrics\n",
    "\n",
    "def two_rv_ttest_power(dataframe,sorting_var,value_var,alpha,amount, ratio):\n",
    "    quick_df = dataframe[[sorting_var,value_var]].groupby(sorting_var)        \n",
    "    rv_one = stats.norm.rvs(loc=quick_df.mean().iloc[0],scale=quick_df.std().iloc[0],size=amount)\n",
    "    rv_two = stats.norm.rvs(loc=quick_df.mean().iloc[1],scale=quick_df.std().iloc[1],size=amount)\n",
    "    ttest = stats.ttest_ind(rv_one,rv_two)\n",
    "    power = statsmodels.stats.power.tt_ind_solve_power(abs(cohen_d(rv_one,rv_two)),amount,alpha,None,ratio,'two-sided')\n",
    "    print(power)\n",
    "    return ttest"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i in range(len(df)):\n",
    "    if df.name.iloc[i] in list(final_team_dict.keys()):\n",
    "        df.team.iloc[i] = final_team_dict[df.name.iloc[i]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
